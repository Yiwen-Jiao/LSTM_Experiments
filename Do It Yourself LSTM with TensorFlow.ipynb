{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do It Yourself LSTM with TensorFlow\n",
    "\n",
    "Based on the post [Understanding LStM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) by Colah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[1, 0, 0],\n",
      "       [0, 1, 0],\n",
      "       [1, 0, 0],\n",
      "       [1, 0, 0],\n",
      "       [0, 0, 0],\n",
      "       [1, 0, 0]])\n",
      "'+-++0+'\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "\n",
    "import data_generator\n",
    "\n",
    "sequence_length = 6\n",
    "\n",
    "reference_input_data, reference_output_data = data_generator.getSequences(sequence_length)\n",
    "\n",
    "# data_generator.getSequences(sequence_length) generates all possible combinations of\n",
    "# the characters '+-0I', so for a sequence length of 6 characters there are a\n",
    "# a total of 4^6 = 4096 possible combinations. Some Examples:\n",
    "# '+-+-+-' = 0\n",
    "# '------' = -6\n",
    "# '0++000' = 2\n",
    "# 'I++000' = -2\n",
    "#\n",
    "# Those sequences are encoded: Every character is representated by a vector, so the actual\n",
    "# return value from data_generator.getSequences looks like this:\n",
    "pprint(reference_input_data[0])\n",
    "\n",
    "# There is a helper to decode that again:\n",
    "pprint(data_generator.decodeSequence(reference_input_data[0]))\n",
    "\n",
    "# The solution for that sequence is:\n",
    "pprint(reference_output_data[0])\n",
    "\n",
    "instruction_count = np.array(reference_input_data).shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We'll train using 1024/4096 Examples\n"
     ]
    }
   ],
   "source": [
    "NUM_EXAMPLES = len(reference_input_data) / 4 # we use 1/4 of the data for the training\n",
    "\n",
    "test_input = reference_input_data[NUM_EXAMPLES:]\n",
    "test_output = reference_output_data[NUM_EXAMPLES:] # everything beyond NUM_EXAMPLES\n",
    "\n",
    "train_input = reference_input_data[:NUM_EXAMPLES]\n",
    "train_output = reference_output_data[:NUM_EXAMPLES]\n",
    "\n",
    "print(\"We'll train using \" + str(NUM_EXAMPLES) + \"/\" + str(len(reference_input_data)) + \" Examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data = tf.placeholder(tf.float32, [None, sequence_length, instruction_count], name='data')\n",
    "target = tf.transpose(tf.placeholder(tf.float32, [None], name='target'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LSTM Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_SIZE = 24\n",
    "FEATURE_SIZE = 3 # Ace of Hearts, Ace of Clubs, King of Spades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default_weights_and_bias():\n",
    "    Weights = tf.Variable(tf.truncated_normal([LSTM_SIZE, LSTM_SIZE + FEATURE_SIZE], -0.2, 0.1))\n",
    "    bias = tf.Variable(tf.constant(0.0, shape = [LSTM_SIZE, 1]))\n",
    "    \n",
    "    return Weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Forget Layer\n",
    "\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-f.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_f, _ = default_weights_and_bias()\n",
    "\n",
    "b_f = tf.Variable(tf.constant(1.0, shape = [LSTM_SIZE, 1]))\n",
    "\n",
    "# The forget layer\n",
    "#\n",
    "# Shapes:\n",
    "#   - W_f: 24x27\n",
    "#   - ht_minus_1_and_xt: 27x?\n",
    "#   - b_f: 24x1\n",
    "#   - f_t: 24x?\n",
    "def f_t(ht_minus_1_and_xt):\n",
    "    return tf.sigmoid(tf.matmul(W_f, ht_minus_1_and_xt) + b_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 New Candidate Conveyor\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-i.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_i, b_i = default_weights_and_bias()\n",
    "\n",
    "# Input Gate Layer\n",
    "#\n",
    "# Shapes:\n",
    "#   - W_i: 24x27\n",
    "#   - ht_minus_1_and_xt: 27x?\n",
    "#   - b_i: 24x1\n",
    "#   - i_t: 24x?\n",
    "def i_t(ht_minus_1_and_xt):\n",
    "    return tf.sigmoid(tf.matmul(W_i, ht_minus_1_and_xt) + b_i)\n",
    "\n",
    "W_C, b_c = default_weights_and_bias()\n",
    "\n",
    "# New Candidates for the Conveyor\n",
    "#\n",
    "# Shapes:\n",
    "#   - W_C: 24x27\n",
    "#   - ht_minus_1_and_xt: 27x?\n",
    "#   - b_c: 24x1\n",
    "#   - candidate_C_t: 24x?\n",
    "def candidate_C_t(ht_minus_1_and_xt):\n",
    "    return tf.tanh(tf.matmul(W_C, ht_minus_1_and_xt) + b_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Update Conveyor\n",
    "\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-C.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Updated Conveyor\n",
    "#\n",
    "# Shapes:\n",
    "#   - f_t: 24x?\n",
    "#   - Conveyor: 24x?\n",
    "#   - i_t: 24x?\n",
    "#   - CandidateConveyor: 24x?\n",
    "def C_t(ht_minus_1_and_xt, Conveyor, CandidateConveyor):\n",
    "    return f_t(ht_minus_1_and_xt) * Conveyor + i_t(ht_minus_1_and_xt) * CandidateConveyor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Prediction (for current LSTM step)\n",
    "\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-o.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_o, b_o = default_weights_and_bias()\n",
    "\n",
    "# Updated Conveyor\n",
    "#\n",
    "# Shapes:\n",
    "#   - W_o: 24x27\n",
    "#   - b_o: 24x1\n",
    "#   - ht_minus_1_and_xt: 27x?\n",
    "#   - FinalConveyor: 24x?\n",
    "#   - o_t: 24x?\n",
    "#   - h_t: 24x?\n",
    "def h_t(ht_minus_1_and_xt, FinalConveyor):\n",
    "    o_t = tf.sigmoid(tf.matmul(W_o, ht_minus_1_and_xt) + b_o)\n",
    "    \n",
    "    return o_t * tf.tanh(FinalConveyor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 The LSTM Cell\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_cell(ht_minus_1_and_Conveyor, xt):\n",
    "    ht_minus_1, Conveyor = ht_minus_1_and_Conveyor\n",
    "    \n",
    "    ht_minus_1_and_xt = tf.transpose(tf.concat([ht_minus_1, xt], 1))\n",
    "    \n",
    "    CandidateConveyor = candidate_C_t(ht_minus_1_and_xt)\n",
    "    \n",
    "    FinalConveyor = C_t(ht_minus_1_and_xt, Conveyor, CandidateConveyor)\n",
    "    \n",
    "    lstm_prediction = tf.transpose(h_t(ht_minus_1_and_xt, FinalConveyor))\n",
    "    \n",
    "    return(lstm_prediction, FinalConveyor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_length = tf.shape(data)[0]\n",
    "\n",
    "# This loop gets called once for every \"timestep\" and obtains one column of the input data\n",
    "def lstm_loop(last_lstm_prediction, last_state, step):\n",
    "    lstm_prediction, state = lstm_cell((last_lstm_prediction, last_state), data[:, step, :])\n",
    "    return lstm_prediction, state, tf.add(step, 1)\n",
    "\n",
    "\n",
    "initial_Conveyor = tf.zeros([LSTM_SIZE, data_length])\n",
    "initial_prediction = tf.zeros([data_length, LSTM_SIZE])\n",
    "\n",
    "timesteps = sequence_length\n",
    "\n",
    "for_each_time_step = lambda a, b, step: tf.less(step, timesteps)\n",
    "\n",
    "lstm_prediction, lstm_state, _ = tf.while_loop(for_each_time_step, lstm_loop, (initial_prediction, initial_Conveyor, 0), parallel_iterations=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([LSTM_SIZE, 1]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[1]))\n",
    "\n",
    "prediction = tf.matmul(lstm_prediction, weight) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cost & Optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mean_square_error_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('mean_square_error'):\n",
    "    mean_square_error = tf.reduce_sum(tf.square(tf.subtract(target, tf.unstack(prediction, axis = 1))))\n",
    "tf.summary.scalar('mean_square_error', mean_square_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "minimize = optimizer.minimize(mean_square_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'error_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('error'):\n",
    "    with tf.name_scope('mistakes'):\n",
    "        mistakes = tf.not_equal(target, tf.round(tf.unstack(prediction, axis = 1)))\n",
    "    with tf.name_scope('error'):\n",
    "        error = tf.reduce_mean(tf.cast(mistakes, tf.float32))\n",
    "tf.summary.scalar('error', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "date = str(datetime.datetime.now())\n",
    "train_writer = tf.summary.FileWriter('logs/selfmade_lstm/' + date + '/train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter('logs/selfmade_lstm/' + date + '/test', sess.graph)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   20 | incorrect  77.4% | mean squ error  8864.7\n",
      "Epoch   40 | incorrect  77.2% | mean squ error  8195.1\n",
      "Epoch   60 | incorrect  73.9% | mean squ error  7601.0\n",
      "Epoch   80 | incorrect  74.5% | mean squ error  7347.5\n",
      "Epoch  100 | incorrect  74.3% | mean squ error  7152.0\n",
      "Epoch  120 | incorrect  74.1% | mean squ error  6922.2\n",
      "Epoch  140 | incorrect  73.6% | mean squ error  6489.1\n",
      "Epoch  160 | incorrect  71.7% | mean squ error  5900.1\n",
      "Epoch  180 | incorrect  70.0% | mean squ error  5317.5\n",
      "Epoch  200 | incorrect  66.7% | mean squ error  4767.0\n",
      "Epoch  220 | incorrect  63.7% | mean squ error  4163.0\n",
      "Epoch  240 | incorrect  60.4% | mean squ error  3602.8\n",
      "Epoch  260 | incorrect  57.7% | mean squ error  3204.3\n",
      "Epoch  280 | incorrect  55.6% | mean squ error  2948.7\n",
      "Epoch  300 | incorrect  54.0% | mean squ error  2746.1\n",
      "Epoch  320 | incorrect  52.2% | mean squ error  2578.6\n",
      "Epoch  340 | incorrect  50.9% | mean squ error  2431.7\n",
      "Epoch  360 | incorrect  49.5% | mean squ error  2296.8\n",
      "Epoch  380 | incorrect  48.0% | mean squ error  2170.4\n",
      "Epoch  400 | incorrect  46.5% | mean squ error  2043.1\n",
      "Epoch  420 | incorrect  44.8% | mean squ error  1918.2\n",
      "Epoch  440 | incorrect  42.5% | mean squ error  1795.7\n",
      "Epoch  460 | incorrect  40.7% | mean squ error  1688.7\n",
      "Epoch  480 | incorrect  38.2% | mean squ error  1582.8\n",
      "Epoch  500 | incorrect  36.2% | mean squ error  1497.6\n",
      "Epoch  520 | incorrect  34.5% | mean squ error  1421.3\n",
      "Epoch  540 | incorrect  33.3% | mean squ error  1359.1\n",
      "Epoch  560 | incorrect  31.9% | mean squ error  1299.5\n",
      "Epoch  580 | incorrect  30.3% | mean squ error  1244.6\n",
      "Epoch  600 | incorrect  29.2% | mean squ error  1191.5\n",
      "Epoch  620 | incorrect  28.1% | mean squ error  1139.1\n",
      "Epoch  640 | incorrect  26.8% | mean squ error  1087.6\n",
      "Epoch  660 | incorrect  25.7% | mean squ error  1037.8\n",
      "Epoch  680 | incorrect  25.1% | mean squ error  1018.0\n",
      "Epoch  700 | incorrect  23.3% | mean squ error  952.1\n",
      "Epoch  720 | incorrect  22.6% | mean squ error  911.0\n",
      "Epoch  740 | incorrect  21.4% | mean squ error  874.6\n",
      "Epoch  760 | incorrect  20.0% | mean squ error  840.1\n",
      "Epoch  780 | incorrect  18.8% | mean squ error  807.3\n",
      "Epoch  800 | incorrect  17.2% | mean squ error  776.9\n",
      "Epoch  820 | incorrect  16.2% | mean squ error  748.4\n",
      "Epoch  840 | incorrect  15.6% | mean squ error  721.6\n",
      "Epoch  860 | incorrect  15.0% | mean squ error  696.2\n",
      "Epoch  880 | incorrect  14.4% | mean squ error  672.1\n",
      "Epoch  900 | incorrect  13.8% | mean squ error  652.5\n",
      "Epoch  920 | incorrect  13.6% | mean squ error  634.4\n",
      "Epoch  940 | incorrect  13.2% | mean squ error  607.0\n",
      "Epoch  960 | incorrect  12.7% | mean squ error  587.1\n",
      "Epoch  980 | incorrect  12.3% | mean squ error  568.2\n",
      "Epoch 1000 | incorrect  11.7% | mean squ error  549.7\n",
      "Epoch 1020 | incorrect  11.4% | mean squ error  531.7\n",
      "Epoch 1040 | incorrect  11.1% | mean squ error  514.1\n",
      "Epoch 1060 | incorrect  11.4% | mean squ error  500.9\n",
      "Epoch 1080 | incorrect  10.7% | mean squ error  483.4\n",
      "Epoch 1100 | incorrect  10.5% | mean squ error  469.5\n",
      "Epoch 1120 | incorrect  10.3% | mean squ error  455.7\n",
      "Epoch 1140 | incorrect  10.2% | mean squ error  442.5\n",
      "Epoch 1160 | incorrect  10.0% | mean squ error  429.8\n",
      "Epoch 1180 | incorrect  9.6% | mean squ error  417.7\n",
      "Epoch 1200 | incorrect  9.4% | mean squ error  406.6\n",
      "Epoch 1220 | incorrect  9.2% | mean squ error  395.8\n",
      "Epoch 1240 | incorrect  9.0% | mean squ error  386.3\n",
      "Epoch 1260 | incorrect  8.7% | mean squ error  377.0\n",
      "Epoch 1280 | incorrect  8.4% | mean squ error  368.2\n",
      "Epoch 1300 | incorrect  8.2% | mean squ error  359.7\n",
      "Epoch 1320 | incorrect  7.9% | mean squ error  351.7\n",
      "Epoch 1340 | incorrect  7.9% | mean squ error  350.4\n",
      "Epoch 1360 | incorrect  7.5% | mean squ error  338.9\n",
      "Epoch 1380 | incorrect  7.4% | mean squ error  331.4\n",
      "Epoch 1400 | incorrect  7.2% | mean squ error  325.5\n",
      "Epoch 1420 | incorrect  6.9% | mean squ error  320.1\n",
      "Epoch 1440 | incorrect  6.5% | mean squ error  315.1\n",
      "Epoch 1460 | incorrect  6.3% | mean squ error  310.3\n",
      "Epoch 1480 | incorrect  6.2% | mean squ error  305.8\n",
      "Epoch 1500 | incorrect  5.8% | mean squ error  301.5\n",
      "Epoch 1520 | incorrect  5.4% | mean squ error  297.4\n",
      "Epoch 1540 | incorrect  6.1% | mean squ error  310.9\n",
      "Epoch 1560 | incorrect  5.3% | mean squ error  292.9\n",
      "Epoch 1580 | incorrect  4.8% | mean squ error  287.0\n",
      "Epoch 1600 | incorrect  4.7% | mean squ error  283.8\n",
      "Epoch 1620 | incorrect  4.5% | mean squ error  281.0\n",
      "Epoch 1640 | incorrect  4.4% | mean squ error  278.1\n",
      "Epoch 1660 | incorrect  4.3% | mean squ error  275.4\n",
      "Epoch 1680 | incorrect  4.2% | mean squ error  272.8\n",
      "Epoch 1700 | incorrect  4.1% | mean squ error  270.2\n",
      "Epoch 1720 | incorrect  3.9% | mean squ error  267.6\n",
      "Epoch 1740 | incorrect  3.8% | mean squ error  265.2\n",
      "Epoch 1760 | incorrect  3.8% | mean squ error  262.8\n",
      "Epoch 1780 | incorrect  3.8% | mean squ error  268.4\n",
      "Epoch 1800 | incorrect  3.4% | mean squ error  266.8\n",
      "Epoch 1820 | incorrect  3.4% | mean squ error  256.7\n",
      "Epoch 1840 | incorrect  3.3% | mean squ error  254.0\n",
      "Epoch 1860 | incorrect  3.2% | mean squ error  252.1\n",
      "Epoch 1880 | incorrect  3.2% | mean squ error  250.2\n",
      "Epoch 1900 | incorrect  3.1% | mean squ error  248.3\n",
      "Epoch 1920 | incorrect  3.1% | mean squ error  246.5\n",
      "Epoch 1940 | incorrect  3.0% | mean squ error  244.6\n",
      "Epoch 1960 | incorrect  2.9% | mean squ error  242.8\n",
      "Epoch 1980 | incorrect  2.8% | mean squ error  241.0\n",
      "Epoch 2000 | incorrect  2.8% | mean squ error  239.2\n",
      "Epoch 2020 | incorrect  2.8% | mean squ error  237.4\n",
      "Epoch 2040 | incorrect  2.7% | mean squ error  235.7\n",
      "Epoch 2060 | incorrect  2.7% | mean squ error  233.9\n",
      "Epoch 2080 | incorrect  2.6% | mean squ error  233.1\n",
      "Epoch 2100 | incorrect  2.6% | mean squ error  231.8\n",
      "Epoch 2120 | incorrect  2.6% | mean squ error  228.9\n",
      "Epoch 2140 | incorrect  2.5% | mean squ error  227.2\n",
      "Epoch 2160 | incorrect  2.5% | mean squ error  225.7\n",
      "Epoch 2180 | incorrect  2.5% | mean squ error  224.3\n",
      "Epoch 2200 | incorrect  2.5% | mean squ error  222.8\n",
      "Epoch 2220 | incorrect  2.5% | mean squ error  221.4\n",
      "Epoch 2240 | incorrect  2.5% | mean squ error  219.9\n",
      "Epoch 2260 | incorrect  2.4% | mean squ error  218.4\n",
      "Epoch 2280 | incorrect  2.4% | mean squ error  216.9\n",
      "Epoch 2300 | incorrect  2.4% | mean squ error  215.5\n",
      "Epoch 2320 | incorrect  2.4% | mean squ error  214.0\n",
      "Epoch 2340 | incorrect  2.4% | mean squ error  212.6\n",
      "Epoch 2360 | incorrect  2.7% | mean squ error  245.7\n",
      "Epoch 2380 | incorrect  2.2% | mean squ error  212.7\n",
      "Epoch 2400 | incorrect  2.3% | mean squ error  208.2\n",
      "Epoch 2420 | incorrect  2.3% | mean squ error  207.2\n",
      "Epoch 2440 | incorrect  2.2% | mean squ error  205.7\n",
      "Epoch 2460 | incorrect  2.3% | mean squ error  204.4\n",
      "Epoch 2480 | incorrect  2.3% | mean squ error  203.1\n",
      "Epoch 2500 | incorrect  2.2% | mean squ error  201.8\n",
      "Epoch 2520 | incorrect  2.2% | mean squ error  200.6\n",
      "Epoch 2540 | incorrect  2.2% | mean squ error  199.3\n",
      "Epoch 2560 | incorrect  2.2% | mean squ error  198.0\n",
      "Epoch 2580 | incorrect  2.2% | mean squ error  196.7\n",
      "Epoch 2600 | incorrect  2.1% | mean squ error  201.9\n",
      "Epoch 2620 | incorrect  2.1% | mean squ error  194.1\n",
      "Epoch 2640 | incorrect  2.1% | mean squ error  193.0\n",
      "Epoch 2660 | incorrect  2.1% | mean squ error  191.6\n",
      "Epoch 2680 | incorrect  2.1% | mean squ error  190.6\n",
      "Epoch 2700 | incorrect  2.1% | mean squ error  189.4\n",
      "Epoch 2720 | incorrect  2.1% | mean squ error  188.3\n",
      "Epoch 2740 | incorrect  2.0% | mean squ error  187.1\n",
      "Epoch 2760 | incorrect  2.0% | mean squ error  186.0\n",
      "Epoch 2780 | incorrect  2.0% | mean squ error  184.8\n",
      "Epoch 2800 | incorrect  2.0% | mean squ error  183.7\n",
      "Epoch 2820 | incorrect  1.9% | mean squ error  182.6\n",
      "Epoch 2840 | incorrect  1.9% | mean squ error  181.4\n",
      "Epoch 2860 | incorrect  1.8% | mean squ error  181.4\n",
      "Epoch 2880 | incorrect  1.7% | mean squ error  185.7\n",
      "Epoch 2900 | incorrect  1.8% | mean squ error  177.8\n",
      "Epoch 2920 | incorrect  1.8% | mean squ error  177.1\n",
      "Epoch 2940 | incorrect  1.8% | mean squ error  176.0\n",
      "Epoch 2960 | incorrect  1.8% | mean squ error  175.0\n",
      "Epoch 2980 | incorrect  1.8% | mean squ error  174.0\n",
      "Epoch 3000 | incorrect  1.8% | mean squ error  173.0\n",
      "Epoch 3020 | incorrect  1.8% | mean squ error  172.0\n",
      "Epoch 3040 | incorrect  1.8% | mean squ error  171.1\n",
      "Epoch 3060 | incorrect  1.7% | mean squ error  170.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3080 | incorrect  1.7% | mean squ error  169.1\n",
      "Epoch 3100 | incorrect  1.7% | mean squ error  168.1\n",
      "Epoch 3120 | incorrect  1.7% | mean squ error  167.1\n",
      "Epoch 3140 | incorrect  1.7% | mean squ error  166.1\n",
      "Epoch 3160 | incorrect  1.7% | mean squ error  165.2\n",
      "Epoch 3180 | incorrect  2.3% | mean squ error  208.6\n",
      "Epoch 3200 | incorrect  1.7% | mean squ error  163.4\n",
      "Epoch 3220 | incorrect  1.7% | mean squ error  162.2\n",
      "Epoch 3240 | incorrect  1.7% | mean squ error  161.2\n",
      "Epoch 3260 | incorrect  1.7% | mean squ error  160.5\n",
      "Epoch 3280 | incorrect  1.7% | mean squ error  159.7\n",
      "Epoch 3300 | incorrect  1.7% | mean squ error  158.8\n",
      "Epoch 3320 | incorrect  1.7% | mean squ error  157.9\n",
      "Epoch 3340 | incorrect  1.7% | mean squ error  157.1\n",
      "Epoch 3360 | incorrect  1.7% | mean squ error  156.2\n",
      "Epoch 3380 | incorrect  1.7% | mean squ error  155.4\n",
      "Epoch 3400 | incorrect  1.7% | mean squ error  154.5\n",
      "Epoch 3420 | incorrect  1.7% | mean squ error  153.7\n",
      "Epoch 3440 | incorrect  1.7% | mean squ error  153.3\n",
      "Epoch 3460 | incorrect  1.6% | mean squ error  160.2\n",
      "Epoch 3480 | incorrect  1.6% | mean squ error  151.8\n",
      "Epoch 3500 | incorrect  1.7% | mean squ error  150.2\n",
      "Epoch 3520 | incorrect  1.7% | mean squ error  149.5\n",
      "Epoch 3540 | incorrect  1.7% | mean squ error  148.8\n",
      "Epoch 3560 | incorrect  1.7% | mean squ error  148.1\n",
      "Epoch 3580 | incorrect  1.7% | mean squ error  147.4\n",
      "Epoch 3600 | incorrect  1.7% | mean squ error  146.6\n",
      "Epoch 3620 | incorrect  1.7% | mean squ error  145.9\n",
      "Epoch 3640 | incorrect  1.7% | mean squ error  145.2\n",
      "Epoch 3660 | incorrect  1.7% | mean squ error  144.4\n",
      "Epoch 3680 | incorrect  1.7% | mean squ error  143.7\n",
      "Epoch 3700 | incorrect  1.7% | mean squ error  143.0\n",
      "Epoch 3720 | incorrect  1.7% | mean squ error  142.3\n",
      "Epoch 3740 | incorrect  1.8% | mean squ error  165.1\n",
      "Epoch 3760 | incorrect  1.5% | mean squ error  144.5\n",
      "Epoch 3780 | incorrect  1.7% | mean squ error  140.1\n",
      "Epoch 3800 | incorrect  1.7% | mean squ error  139.7\n",
      "Epoch 3820 | incorrect  1.7% | mean squ error  138.9\n",
      "Epoch 3840 | incorrect  1.7% | mean squ error  138.2\n",
      "Epoch 3860 | incorrect  1.7% | mean squ error  137.6\n",
      "Epoch 3880 | incorrect  1.7% | mean squ error  137.0\n",
      "Epoch 3900 | incorrect  1.7% | mean squ error  136.4\n",
      "Epoch 3920 | incorrect  1.7% | mean squ error  135.8\n",
      "Epoch 3940 | incorrect  1.7% | mean squ error  135.2\n",
      "Epoch 3960 | incorrect  1.7% | mean squ error  134.6\n",
      "Epoch 3980 | incorrect  1.6% | mean squ error  134.0\n",
      "Epoch 4000 | incorrect  1.6% | mean squ error  133.4\n"
     ]
    }
   ],
   "source": [
    "epoch = 4000\n",
    "\n",
    "for i in range(epoch):\n",
    "    if (i + 1) % 20 == 0:\n",
    "        summary, incorrect, mean_squ_err = sess.run([merged, error, mean_square_error], {data: test_input, target: test_output})\n",
    "        test_writer.add_summary(summary, i)\n",
    "        \n",
    "        print('Epoch {:4d} | incorrect {: 3.1f}% | mean squ error {: 3.1f}'.format(i + 1, incorrect * 100, mean_squ_err))\n",
    "    else:\n",
    "        summary, acc = sess.run([merged, error], {data: train_input, target: train_output})\n",
    "        train_writer.add_summary(summary, i)\n",
    "    \n",
    "    sess.run(minimize,{data: train_input, target: train_output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.98095763]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the result\n",
    "sess.run(prediction, {data: [data_generator.encodeSequence(\"00-+++\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "train_writer.close()\n",
    "test_writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
