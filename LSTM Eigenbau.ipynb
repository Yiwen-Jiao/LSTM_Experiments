{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding LSTM Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Datenaufbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0, 0, 0],\n",
      "       [0, 0, 1],\n",
      "       [1, 0, 0],\n",
      "       [0, 1, 0],\n",
      "       [0, 1, 0],\n",
      "       [0, 0, 1]])\n",
      "'0I+--I'\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "\n",
    "import trainer\n",
    "reload(trainer)\n",
    "\n",
    "sequence_length = 6\n",
    "\n",
    "reference_input_data, reference_output_data = trainer.getSequences(sequence_length)\n",
    "\n",
    "# trainer.getSequences(sequence_length) generates all possible combinations of\n",
    "# the characters '+-0I', so for a sequence length of 6 characters there are a\n",
    "# a total of 4^6 = 4096 possible combinations. Some Examples:\n",
    "# '+-+-+-' = 0\n",
    "# '------' = -6\n",
    "# '0++000' = 2\n",
    "# 'I++000' = -2\n",
    "#\n",
    "# Those sequences are encoded: Every character is representated by a vector, so the actual\n",
    "# return value from trainer.getSequences looks like this:\n",
    "pprint(reference_input_data[0])\n",
    "\n",
    "# There is a helper to decode that again:\n",
    "pprint(trainer.decodeSequence(reference_input_data[0]))\n",
    "\n",
    "# The solution for that sequence is:\n",
    "pprint(reference_output_data[0])\n",
    "\n",
    "instruction_count = np.array(reference_input_data).shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We'll train using 1024/4096 Examples\n"
     ]
    }
   ],
   "source": [
    "NUM_EXAMPLES = len(reference_input_data) / 4 # we use 1/4 of the data for the training\n",
    "\n",
    "test_input = reference_input_data[NUM_EXAMPLES:]\n",
    "test_output = reference_output_data[NUM_EXAMPLES:] # everything beyond NUM_EXAMPLES\n",
    "\n",
    "train_input = reference_input_data[:NUM_EXAMPLES]\n",
    "train_output = reference_output_data[:NUM_EXAMPLES]\n",
    "\n",
    "print(\"We'll train using \" + str(NUM_EXAMPLES) + \"/\" + str(len(reference_input_data)) + \" Examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data = tf.placeholder(tf.float32, [None, sequence_length, instruction_count], name='data')\n",
    "target = tf.transpose(tf.placeholder(tf.float32, [None], name='target'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Die LSTM Schicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_SETTINGS = {\n",
    "    'num_cells': 24,\n",
    "    'feature_size': 3\n",
    "}\n",
    "\n",
    "# All of the LSTM's weights and biases (should?!) have the same dimensions, so we'd rather don't repeat ourselves\n",
    "def default_weights_and_bias():\n",
    "    weights = tf.Variable(tf.truncated_normal([LSTM_SETTINGS['num_cells'], LSTM_SETTINGS['num_cells'] + LSTM_SETTINGS['feature_size']]))\n",
    "#   Alternative?!:    weights = tf.transpose(tf.Variable(tf.truncated_normal([LSTM_SETTINGS['num_cells'], LSTM_SETTINGS['num_cells'] + LSTM_SETTINGS['feature_size']])))\n",
    "    bias = tf.transpose(tf.Variable(tf.constant(0.1, shape = [LSTM_SETTINGS['num_cells']])))\n",
    "#   Alternative?!:    bias = tf.Variable(tf.constant(0.1, shape = [LSTM_SETTINGS['num_cells']]))\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Forget Layer\n",
    "\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-f.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_forget_layer, b_forget_layer = default_weights_and_bias()\n",
    "\n",
    "def forget_layer(ht_minus_1_and_xt):\n",
    "    print(\"ft: W\", str(W_forget_layer.get_shape()))\n",
    "    print(\"ft: ht_minus_1_and_xt\", str(ht_minus_1_and_xt.get_shape()))\n",
    "    print(\"ft: b_forget_layer\", str(b_forget_layer.get_shape()))\n",
    "    ft = tf.sigmoid(tf.transpose(tf.matmul(W_forget_layer, tf.transpose(ht_minus_1_and_xt))) + b_forget_layer)\n",
    "#   Alternative?!:   ft = tf.sigmoid(tf.matmul(ht_minus_1_and_xt, W_forget_layer) + b_forget_layer)\n",
    "    print(\"ft: ft\", str(ft.get_shape()))\n",
    "\n",
    "    return(ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Input Layer\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-i.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_input_layer, b_input_layer = default_weights_and_bias()\n",
    "\n",
    "def input_gate_layer(ht_minus_1_and_xt):\n",
    "    it = tf.sigmoid(tf.transpose(tf.matmul(W_input_layer, tf.transpose(ht_minus_1_and_xt))) + b_input_layer)\n",
    "#   Alternative?!:    it = tf.sigmoid(tf.matmul(ht_minus_1_and_xt, W_input_layer) + b_input_layer)\n",
    "    return it\n",
    "\n",
    "W_candiate_layer, b_candiate_layer = default_weights_and_bias()\n",
    "\n",
    "def new_candidate_values_layer(ht_minus_1_and_xt):\n",
    "    C_candidate = tf.tanh(tf.transpose(tf.matmul(W_candiate_layer, tf.transpose(ht_minus_1_and_xt))) + b_candiate_layer)\n",
    "#   Alternative?!:    C_candidate = tf.tanh(tf.matmul(ht_minus_1_and_xt, W_candiate_layer) + b_candiate_layer)\n",
    "    \n",
    "    return C_candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Update Layer\n",
    "\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-C.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_conveyor(ft, it, Conveyor, CandidateConveyor):\n",
    "    print(\"############\")\n",
    "    print(\"update_conveyor: ft\", str(ft.get_shape()))\n",
    "    print(\"update_conveyor: Conveyor\", str(Conveyor.get_shape()))\n",
    "    print(\"update_conveyor: it\", str(it.get_shape()))\n",
    "    print(\"update_conveyor: CandidateConveyor\", str(CandidateConveyor.get_shape()))\n",
    "    new_Conveyor = ft * Conveyor + it * CandidateConveyor\n",
    "    return(new_Conveyor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Output Layer\n",
    "\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-o.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_prediction_layer, b_prediction_layer = default_weights_and_bias()\n",
    "    \n",
    "def output_layer(ht_minus_1_and_xt, new_Conveyor):\n",
    "    ot = tf.sigmoid(tf.transpose(tf.matmul(W_prediction_layer, tf.transpose(ht_minus_1_and_xt))) + b_prediction_layer)\n",
    "#   Alternative?!: ot = tf.sigmoid(tf.matmul(ht_minus_1_and_xt, W_prediction_layer) + b_prediction_layer)\n",
    "    prediction = ot * tf.tanh(new_Conveyor)\n",
    "    return(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 The LSTM Cell â€“ Putting it all together\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_cell(ht_minus_1_and_Conveyor, xt):\n",
    "    ht_minus_1, Conveyor = ht_minus_1_and_Conveyor\n",
    "    \n",
    "    ht_minus_1_and_xt = tf.concat([ht_minus_1, xt], 1)\n",
    "    \n",
    "    ft                = forget_layer(ht_minus_1_and_xt)\n",
    "    it                = input_gate_layer(ht_minus_1_and_xt)\n",
    "    CandidateConveyor = new_candidate_values_layer(ht_minus_1_and_xt) # CandidateConveyor entspricht ~C_t\n",
    "    \n",
    "    new_Conveyor = update_conveyor(ft, it, Conveyor, CandidateConveyor)\n",
    "    \n",
    "    lstm_prediction = output_layer(ht_minus_1_and_xt, new_Conveyor)\n",
    "    \n",
    "    return(lstm_prediction, new_Conveyor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ft: W', '(24, 27)')\n",
      "('ft: ht_minus_1_and_xt', '(?, 27)')\n",
      "('ft: b_forget_layer', '(24,)')\n",
      "('ft: ft', '(?, 24)')\n",
      "############\n",
      "('update_conveyor: ft', '(?, 24)')\n",
      "('update_conveyor: Conveyor', '(?, 24)')\n",
      "('update_conveyor: it', '(?, 24)')\n",
      "('update_conveyor: CandidateConveyor', '(?, 24)')\n"
     ]
    }
   ],
   "source": [
    "data_length = tf.shape(data)[0]\n",
    "\n",
    "initial_Conveyor = tf.zeros([data_length, LSTM_SETTINGS['num_cells']])\n",
    "initial_prediction = tf.zeros([data_length, LSTM_SETTINGS['num_cells']])\n",
    "\n",
    "# This loop gets called once for every \"timestep\" and gets one column of the input data\n",
    "def lstm_loop(last_lstm_prediction, last_state, step):\n",
    "    lstm_prediction, state = lstm_cell([last_lstm_prediction, last_state], data[:, step, :])\n",
    "    return lstm_prediction, state, tf.add(step, 1)\n",
    "\n",
    "\n",
    "timesteps = sequence_length\n",
    "\n",
    "for_each_time_step = lambda a, b, step: tf.less(step, timesteps)\n",
    "\n",
    "lstm_prediction, lstm_state, _ = tf.while_loop(for_each_time_step, lstm_loop, (initial_prediction, initial_Conveyor, 0), back_prop = True, parallel_iterations=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([LSTM_SETTINGS['num_cells'], 1]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[1]))\n",
    "\n",
    "prediction = tf.matmul(lstm_prediction, weight) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cost & Optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mean_square_error_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('mean_square_error'):\n",
    "    mean_square_error = tf.reduce_sum(tf.square(tf.subtract(target, tf.unstack(prediction, axis = 1))))\n",
    "tf.summary.scalar('mean_square_error', mean_square_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "minimize = optimizer.minimize(mean_square_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'error_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('error'):\n",
    "    with tf.name_scope('mistakes'):\n",
    "        mistakes = tf.not_equal(target, tf.round(tf.unstack(prediction, axis = 1)))\n",
    "    with tf.name_scope('error'):\n",
    "        error = tf.reduce_mean(tf.cast(mistakes, tf.float32))\n",
    "tf.summary.scalar('error', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "date = str(datetime.datetime.now())\n",
    "train_writer = tf.summary.FileWriter('logs/selfmade_lstm/' + date + '/train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter('logs/selfmade_lstm/' + date + 'test')\n",
    "\n",
    "model_checkpoint = 'lstm_self_built.chkpt'\n",
    "\n",
    "tf_saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   20 | incorrect  77.3% | mean squ error  9712.2\n",
      "Epoch   40 | incorrect  73.8% | mean squ error  7820.1\n",
      "Epoch   60 | incorrect  72.4% | mean squ error  6820.1\n",
      "Epoch   80 | incorrect  70.9% | mean squ error  6157.0\n",
      "Epoch  100 | incorrect  70.0% | mean squ error  5650.4\n",
      "Epoch  120 | incorrect  69.0% | mean squ error  5258.0\n",
      "Epoch  140 | incorrect  68.2% | mean squ error  4933.2\n",
      "Epoch  160 | incorrect  67.0% | mean squ error  4647.6\n",
      "Epoch  180 | incorrect  66.2% | mean squ error  4392.8\n",
      "Epoch  200 | incorrect  65.6% | mean squ error  4163.2\n",
      "Epoch  220 | incorrect  64.6% | mean squ error  3954.8\n",
      "Epoch  240 | incorrect  64.0% | mean squ error  3762.8\n",
      "Epoch  260 | incorrect  63.1% | mean squ error  3582.6\n",
      "Epoch  280 | incorrect  62.0% | mean squ error  3410.8\n",
      "Epoch  300 | incorrect  60.6% | mean squ error  3245.3\n",
      "Epoch  320 | incorrect  59.7% | mean squ error  3086.0\n",
      "Epoch  340 | incorrect  58.7% | mean squ error  2933.5\n",
      "Epoch  360 | incorrect  57.1% | mean squ error  2788.9\n",
      "Epoch  380 | incorrect  56.3% | mean squ error  2652.9\n",
      "Epoch  400 | incorrect  54.9% | mean squ error  2526.7\n",
      "Epoch  420 | incorrect  53.7% | mean squ error  2411.4\n",
      "Epoch  440 | incorrect  52.5% | mean squ error  2307.7\n",
      "Epoch  460 | incorrect  52.0% | mean squ error  2215.1\n",
      "Epoch  480 | incorrect  51.2% | mean squ error  2132.7\n",
      "Epoch  500 | incorrect  50.2% | mean squ error  2058.9\n",
      "Epoch  520 | incorrect  48.8% | mean squ error  1992.5\n",
      "Epoch  540 | incorrect  47.9% | mean squ error  1932.4\n",
      "Epoch  560 | incorrect  47.3% | mean squ error  1877.5\n",
      "Epoch  580 | incorrect  46.4% | mean squ error  1827.1\n",
      "Epoch  600 | incorrect  45.5% | mean squ error  1780.2\n",
      "Epoch  620 | incorrect  44.6% | mean squ error  1736.4\n",
      "Epoch  640 | incorrect  43.9% | mean squ error  1695.1\n",
      "Epoch  660 | incorrect  43.3% | mean squ error  1655.9\n",
      "Epoch  680 | incorrect  42.9% | mean squ error  1618.7\n",
      "Epoch  700 | incorrect  42.5% | mean squ error  1583.2\n",
      "Epoch  720 | incorrect  42.1% | mean squ error  1549.2\n",
      "Epoch  740 | incorrect  41.5% | mean squ error  1516.7\n",
      "Epoch  760 | incorrect  41.0% | mean squ error  1485.5\n",
      "Epoch  780 | incorrect  40.3% | mean squ error  1455.6\n",
      "Epoch  800 | incorrect  39.7% | mean squ error  1426.9\n",
      "Epoch  820 | incorrect  38.9% | mean squ error  1399.5\n",
      "Epoch  840 | incorrect  38.3% | mean squ error  1373.3\n",
      "Epoch  860 | incorrect  37.8% | mean squ error  1348.3\n",
      "Epoch  880 | incorrect  37.4% | mean squ error  1324.5\n",
      "Epoch  900 | incorrect  36.8% | mean squ error  1301.7\n",
      "Epoch  920 | incorrect  36.6% | mean squ error  1280.0\n",
      "Epoch  940 | incorrect  36.1% | mean squ error  1259.3\n",
      "Epoch  960 | incorrect  35.6% | mean squ error  1239.4\n",
      "Epoch  980 | incorrect  34.8% | mean squ error  1220.4\n",
      "Epoch 1000 | incorrect  34.5% | mean squ error  1202.1\n",
      "Epoch 1020 | incorrect  33.7% | mean squ error  1184.5\n",
      "Epoch 1040 | incorrect  33.1% | mean squ error  1167.6\n",
      "Epoch 1060 | incorrect  32.5% | mean squ error  1151.2\n",
      "Epoch 1080 | incorrect  32.0% | mean squ error  1135.3\n",
      "Epoch 1100 | incorrect  31.6% | mean squ error  1120.0\n",
      "Epoch 1120 | incorrect  31.1% | mean squ error  1105.2\n",
      "Epoch 1140 | incorrect  30.8% | mean squ error  1090.8\n",
      "Epoch 1160 | incorrect  30.5% | mean squ error  1077.1\n",
      "Epoch 1180 | incorrect  29.9% | mean squ error  1063.8\n",
      "Epoch 1200 | incorrect  29.7% | mean squ error  1051.0\n",
      "Epoch 1220 | incorrect  29.3% | mean squ error  1038.8\n",
      "Epoch 1240 | incorrect  29.3% | mean squ error  1027.0\n",
      "Epoch 1260 | incorrect  29.0% | mean squ error  1015.7\n",
      "Epoch 1280 | incorrect  28.6% | mean squ error  1004.9\n",
      "Epoch 1300 | incorrect  28.2% | mean squ error  994.5\n",
      "Epoch 1320 | incorrect  27.9% | mean squ error  984.6\n",
      "Epoch 1340 | incorrect  27.6% | mean squ error  975.0\n",
      "Epoch 1360 | incorrect  27.3% | mean squ error  965.8\n",
      "Epoch 1380 | incorrect  27.0% | mean squ error  956.9\n",
      "Epoch 1400 | incorrect  26.9% | mean squ error  948.3\n",
      "Epoch 1420 | incorrect  26.7% | mean squ error  940.1\n"
     ]
    }
   ],
   "source": [
    "epoch = 4000\n",
    "\n",
    "for i in range(epoch):\n",
    "    if (i + 1) % 20 == 0:\n",
    "        summary, incorrect, mean_squ_err = sess.run([merged, error, mean_square_error], {data: test_input, target: test_output})\n",
    "        test_writer.add_summary(summary, i)\n",
    "        \n",
    "        print('Epoch {:4d} | incorrect {: 3.1f}% | mean squ error {: 3.1f}'.format(i + 1, incorrect * 100, mean_squ_err))\n",
    "    else:\n",
    "        summary, acc = sess.run([merged, error], {data: train_input, target: train_output})\n",
    "        train_writer.add_summary(summary, i)\n",
    "    \n",
    "    sess.run(minimize,{data: train_input, target: train_output})\n",
    "    \n",
    "    if i % 100:\n",
    "        tf_saver.save(sess, model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reload(trainer)\n",
    "sess.run(prediction, {data: [trainer.encodeSequence(\"II++++\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sess.close()\n",
    "# train_writer.close()\n",
    "# test_writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
